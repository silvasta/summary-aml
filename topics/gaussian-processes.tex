\section{Gaussian Processes (GPs)}

Distribution over functions $f(\mathbf{x})$,
defined by  mean function $m(\mathbf{x}) = 0$ (zero-mean prior)
and covariance (kernel) function $k(\mathbf{x}, \mathbf{x}')$.
\\
For any finite set of inputs
$\mathbf{X} = [\mathbf{x}_1, \dots, \mathbf{x}_n]$,
$\mathbf{f} = [f(\mathbf{x}_1), \dots, f(\mathbf{x}_n)]^T \sim
\mathcal{N}(\mathbf{0}, \mathbf{K})$,
where $\mathbf{K}_{ij} = k(\mathbf{x}_i, \mathbf{x}_j)$.

Intuition: GPs sample smooth functions; non-parametric,
infinite-dimensional Bayesian linear regression. Prior: Multivariate
Gaussian $\mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$ with
$\boldsymbol{\mu} = \mathbf{0}$, $\boldsymbol{\Sigma} = \mathbf{K} +
\sigma_n^2 \mathbf{I}$ (noisy)

Posterior: $\mathbf{y} = \mathbf{f} +
\boldsymbol{\epsilon}$, $\boldsymbol{\epsilon} \sim
\mathcal{N}(\mathbf{0}, \sigma_n^2 \mathbf{I})$.

Joint: $
\begin{bmatrix} \mathbf{y} \\ f_*
\end{bmatrix} \sim \mathcal{N} \left( \mathbf{0},
  \begin{bmatrix} \mathbf{K} + \sigma_n^2 \mathbf{I} & \mathbf{k}_*
    \\ \mathbf{k}_*^T & k(\mathbf{x}_*, \mathbf{x}_*)
\end{bmatrix} \right)$

$f_* | \mathbf{X}, \mathbf{y}, \mathbf{x}_* \sim \mathcal{N}(\mu_*,
\sigma_*^2)$,
$\mu_* = \mathbf{k}_*^T (\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{y}$,
$\sigma_*^2 = k(\mathbf{x}_*, \mathbf{x}_*) - \mathbf{k}_*^T
(\mathbf{K} + \sigma_n^2 \mathbf{I})^{-1} \mathbf{k}_*$

